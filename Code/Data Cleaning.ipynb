{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjG5Eq58xXjt",
        "outputId": "6b3be21c-c149-4d48-b258-0f8e32564440"
      },
      "outputs": [],
      "source": [
        "! pip install dabl\n",
        "import dabl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II1aoE1HHtJI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import GroupKFold,train_test_split,cross_validate\n",
        "from sklearn import tree\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
        "from sklearn.model_selection import KFold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYsK4Sl4lo0n",
        "outputId": "f5e778af-51f8-4953-e0b1-b3b8df9e005e"
      },
      "outputs": [],
      "source": [
        "# Load Datasets\n",
        "df_crash_general = pd.read_csv(\"/content/drive/My Drive/Datathon/crash_info_general.csv\")\n",
        "df_crash_flag = pd.read_csv(\"/content/drive/My Drive/Datathon/crash_info_flag_variables.csv\")\n",
        "df_crash_vehicles = pd.read_csv(\"/content/drive/My Drive/Datathon/crash_info_vehicles.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BycmqP85p-sh",
        "outputId": "2370a740-a1fe-4175-c76a-7a76e4736aee"
      },
      "outputs": [],
      "source": [
        "# Merge datasets based on CRN and drop columns\n",
        "general_mod = df_crash_general.iloc[:,[1,2,12,14,15,18,19,20,21,35,36,38,39,42,44,48,61,63,69,70,71,72,80,95,96,98,99,100]]\n",
        "flag_mod = df_crash_flag.drop(columns=['FATAL','FATAL_OR_SUSP_SERIOUS_INJ','FIRE_IN_VEHICLE','POSSIBLE_INJURY','PROPERTY_DAMAGE_ONLY','INJURY_OR_FATAL'])\n",
        "df_merged = pd.merge(flag_mod,general_mod,on='CRN')\n",
        "vehicles_mod = df_crash_vehicles.drop(columns=['AVOID_MAN_CD','COMM_VEH','EMERG_VEH_USE_CD','PRIN_IMP_PT','UNDER_RIDE_IND','VEH_REG_STATE'])\n",
        "df_merged = pd.merge(df_merged, vehicles_mod, on='CRN')\n",
        "\n",
        "# Select only vehicles that are 1.0: Striking or 3.0: Striking and Struck\n",
        "df_merged = df_merged[df_merged[\"VEH_ROLE\"].isin([1.0,3.0])]\n",
        "\n",
        "# Select only non-secondary crashes\n",
        "df_merged = df_merged[df_merged[\"SECONDARY_CRASH\"] != \"Y\"]\n",
        "\n",
        "# Drop more columns\n",
        "df_merged = df_merged.drop(columns = ['ARRIVAL_TM',\"DISPATCH_TM\" ,\"TIME_OF_DAY\", \"MAKE_CD\",\"MODEL_YR\",\"TRAVEL_DIRECTION\",'PARTIAL_VIN','VINA_BODY_TYPE_CD','DAMAGE_IND','INJURY','SUSPECTED_MINOR_INJURY','SUSPECTED_SERIOUS_INJURY'])\n",
        "df_merged.dropna(subset=['DEC_LAT', 'DEC_LONG', 'fips','HOUR_OF_DAY','TRAVEL_SPD' ], inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "hU-1v47ODQIy",
        "outputId": "163a2f13-e094-4a6e-ab5b-4232495bf57e"
      },
      "outputs": [],
      "source": [
        "# Replacing null values with either 0 or the respective unknown values\n",
        "cols_to_replace = ['SECONDARY_CRASH','INTERSECTION_RELATED']\n",
        "df_merged[cols_to_replace] = df_merged[cols_to_replace].fillna(0)\n",
        "cols_to_replace2 = ['SCH_ZONE_IND','TFC_DETOUR_IND','TRL_VEH_CNT']\n",
        "df_merged[cols_to_replace2] = df_merged[cols_to_replace2].fillna(0)\n",
        "cols_to_replace0 = ['HORSE_BUGGY','LIMIT_70MPH','INS_IND','TRL_VEH_CNT']\n",
        "df_merged[cols_to_replace0] = df_merged[cols_to_replace0].fillna(0)\n",
        "cols_to_replace9 = ['ILLUMINATION','TCD_FUNC_CD','GRADE','RDWY_ALIGNMENT']\n",
        "df_merged[cols_to_replace9] = df_merged[cols_to_replace9].fillna(9)\n",
        "cols_to_replace99 = ['BODY_TYPE','IMPACT_POINT','OWNER_DRIVER','SPECIAL_USAGE','VEH_COLOR_CD','VEH_MOVEMENT','VEH_POSITION','VEH_TYPE']\n",
        "df_merged[cols_to_replace99] = df_merged[cols_to_replace99].fillna(99)\n",
        "cols_to_replace1 = ['DVR_PRES_IND']\n",
        "df_merged[cols_to_replace1] = df_merged[cols_to_replace1].fillna(1)\n",
        "\n",
        "# Standardising string data type to numeric\n",
        "df_merged.replace({'Y':1,'N':0, 'U':-1},inplace=True)\n",
        "\n",
        "df_merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyB__PZHHJEa",
        "outputId": "df8ef02d-e049-485f-c86a-8e8041a3953b"
      },
      "outputs": [],
      "source": [
        "# Keeping only estimated travel speed of less than 200mph\n",
        "data_filtered_speed = df_merged[df_merged['TRAVEL_SPD']<200]\n",
        "data_filtered_speed.info() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "RxplkDaH56r2",
        "outputId": "377660e3-27ed-4e5c-ced7-80f2e8312fbd"
      },
      "outputs": [],
      "source": [
        "# Binary encoding of weather data \n",
        "df_merged['Blowing Sand'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 1, 1, 0)\n",
        "df_merged['Blowing Snow'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 2, 1, 0)\n",
        "df_merged['Clear'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 3, 1, 0)\n",
        "df_merged['Cloudy'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 4, 1, 0)\n",
        "df_merged['Fog/Smog/Smoke'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 5, 1, 0)\n",
        "df_merged['Freezing Rain'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 6, 1, 0)\n",
        "df_merged['Rain'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 7, 1, 0)\n",
        "df_merged['Severe Crosswinds'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 8, 1, 0)\n",
        "df_merged['Sleet/Hail'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 9, 1, 0)\n",
        "df_merged['Snow'] = np.where(df_merged['WEATHER1' or 'WEATHER2'] == 10, 1, 0)\n",
        "df_merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aplFhVmBO664",
        "outputId": "ed5795f0-ef37-4462-bb16-2e501a1b8600"
      },
      "outputs": [],
      "source": [
        "duplicate_ids = df_merged[df_merged.duplicated(subset='CRN', keep=0)]['CRN'].unique()\n",
        "duplicate_ids.size #Number of duplicated CRNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "vqoCVQCCVJLo",
        "outputId": "a97cd730-f8af-4d76-f529-318a6234db15"
      },
      "outputs": [],
      "source": [
        "df_all_int = df_merged.drop(columns=[\"LATITUDE\",\"LONGITUDE\"])\n",
        "df_merged = df_all_int\n",
        "pd.set_option('display.max_rows',None)\n",
        "print(df_all_int.info())\n",
        "print(df_all_int.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erFh8ssmFTzV",
        "outputId": "4dc3f4e8-f42e-4b83-dfbc-f3ae3d0b59da"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering \n",
        "# Hour Of Day, Illumination, Vehicle Body Type, Driver Presence Indicator, Backup\n",
        "\n",
        "# Binary encoding for Hour Of Day\n",
        "dawn = df_merged['HOUR_OF_DAY'] >= 6\n",
        "dusk = df_merged['HOUR_OF_DAY'] <= 18\n",
        "df_merged['DAY'] = np.where(dawn & dusk , 1, 0)\n",
        "\n",
        "# Drop other/unknown illumination\n",
        "df_merged = df_merged[df_merged['ILLUMINATION'] != (8 or 9)]\n",
        "# Daylight, Dimmed (Dusk/dawn), Dark (with streetlight/other lighting), Dark\n",
        "brightness_cond = [df_merged['ILLUMINATION'] == 1,\n",
        "                   df_merged['ILLUMINATION'] == (4 or 5),\n",
        "                   df_merged['ILLUMINATION'] == (3 or 6), \n",
        "                   df_merged['ILLUMINATION'] == 2]\n",
        "brightness_out = [4,3,2,1]   \n",
        "df_merged['BRIGHTNESS'] = np.select(brightness_cond,brightness_out)\n",
        "\n",
        "# Re-categorise vehicle body type into: Car, Motorcycle, Bus, Van, Trucks/Heavy duty represented by 1-5\n",
        "df_merged = df_merged.drop(columns =[\"MOTORCYCLE\",\"SCHOOL_BUS\",'HVY_TRUCK_RELTED'],axis = 1)\n",
        "veh_cond = [df_merged['BODY_TYPE'] >= 1, df_merged['BODY_TYPE'] <=19, \n",
        "            df_merged['BODY_TYPE'] >= 20, df_merged['BODY_TYPE'] <=29,\n",
        "            df_merged['BODY_TYPE'] >= 30, df_merged['BODY_TYPE'] <=39,\n",
        "            df_merged['BODY_TYPE'] >= 40, df_merged['BODY_TYPE'] <=49,\n",
        "            df_merged['BODY_TYPE'] >= 50, df_merged['BODY_TYPE'] <=79]\n",
        "veh_out = [1,1,2,2,3,3,4,4,5,5] \n",
        "df_merged['4-WHEEL'] = np.where(veh_cond[0] & veh_cond[1], 1, 0)\n",
        "df_merged['MOTORCYCLE'] = np.where(veh_cond[2] & veh_cond[3], 1, 0)  \n",
        "df_merged['BUS'] = np.where(veh_cond[4] & veh_cond[5], 1, 0)  \n",
        "df_merged['VAN'] = np.where(veh_cond[6] & veh_cond[7], 1, 0) \n",
        "df_merged['HEAVY_VEHICLES'] = np.where(veh_cond[8] & veh_cond[9], 1, 0)  \n",
        "\n",
        "# Creating new features 'DRUNK/DRUGGED' and 'SICK/FATIGUED/ASLEEP' \n",
        "sober_cond = [df_merged['DVR_PRES_IND'] == 2 ,df_merged['DVR_PRES_IND'] == 3, df_merged['DVR_PRES_IND'] == 7,\n",
        "              df_merged['DVR_PRES_IND'] == 4, df_merged['DVR_PRES_IND'] == 5, df_merged['DVR_PRES_IND'] == 6]\n",
        "df_merged['DRUNK/DRUGGED'] = np.where(sober_cond[0] | sober_cond[1] | sober_cond[2] , 1, 0)  \n",
        "df_merged['SICK/FATIGUED/ASLEEP'] = np.where(sober_cond[3] | sober_cond[4] | sober_cond[5], 1, 0)  \n",
        "#Removing duplicate columns: 'IMPAIRED_DRIVER', 'FATIGUE_ASLEEP'\n",
        "df_merged = df_merged.drop(columns = [\"IMPAIRED_DRIVER\",\"FATIGUE_ASLEEP\"],axis = 1)\n",
        "\n",
        "# Merging all 3 Backup columns into single BACKUP column\n",
        "traffic_cond = (df_merged['BACKUP_PRIOR'] == 1) | (df_merged['BACKUP_NONRECURRING'] == 1) | (df_merged['BACKUP_CONGESTION'] == 1)\n",
        "df_merged['BACKUP'] = np.where(traffic_cond, 1, 0)\n",
        "\n",
        "# Remove all additional columns\n",
        "df_merged = df_merged.drop(columns = ['BACKUP_PRIOR', 'BACKUP_NONRECURRING', 'BACKUP_CONGESTION','WEATHER1','WEATHER2','SECONDARY_CRASH'],axis =1 )  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMsn9FxzOa4Z",
        "outputId": "420211cf-b572-4c32-a29a-14afde0601ae"
      },
      "outputs": [],
      "source": [
        "# Remove all vehicle columns that were not merged\n",
        "end_id = df_merged.columns.get_loc('BODY_TYPE')\n",
        "start_id = df_merged.columns.get_loc('Blowing Sand')\n",
        "TRAVEL_SPD = df_merged.TRAVEL_SPD\n",
        "INS_IND = df_merged.INS_IND\n",
        "df_merged_rowsdeleted = df_merged.drop(df_merged.columns[end_id:start_id],axis = 1)\n",
        "df_merged_rowsdeleted[\"TRAVEL_SPD\"] = TRAVEL_SPD\n",
        "df_merged_rowsdeleted[\"INS_IND\"] = INS_IND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo6QC1bKaB69"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate CRNs, keeping vehicle info and max speed\n",
        "df_merged_rowsdeleted = df_merged_rowsdeleted[df_merged_rowsdeleted['TRAVEL_SPD'] < 200]\n",
        "\n",
        "def remove_duplicates(group) :\n",
        "    merged_row = group.loc[group['TRAVEL_SPD'].idxmax()]\n",
        "    #merged_row = group.loc[group['LANE_COUNT'].idxmax()]\n",
        "    \n",
        "    # Add a 1 for columns 'car', 'motorcycle', 'truck', 'van', 'bus'\n",
        "    # if they are True for the duplicate rows\n",
        "    vehicle_columns = ['4-WHEEL', 'MOTORCYCLE', 'BUS', 'VAN', 'HEAVY_VEHICLES', 'DRUNK/DRUGGED', 'SICK/FATIGUED/ASLEEP','INS_IND']\n",
        "    for col in vehicle_columns:\n",
        "        merged_row[col] = np.where(group[col].any(), 1, merged_row[col])\n",
        "    return merged_row\n",
        "\n",
        "df_noDuplicates = df_merged_rowsdeleted.groupby('CRN',sort=True,as_index=False).apply(remove_duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "pMYTlM2LXIz0",
        "outputId": "35e3e00a-93e4-42c0-dbc7-77cb01712638"
      },
      "outputs": [],
      "source": [
        "# Drop unknown severity and unknown in injured\n",
        "df_noDuplicates = df_noDuplicates[(df_noDuplicates['MAX_SEVERITY_LEVEL'] != 8) & (df_noDuplicates['MAX_SEVERITY_LEVEL'] != 9)]\n",
        "\n",
        "# Replace unknwon brightness with 3(BRIGHT) if clear and day, replace with 1 (Dark) if clear and night\n",
        "df_noDuplicates.loc[(df_noDuplicates['Clear'] == 1) & (df_noDuplicates['DAY'] == 1) & (df_noDuplicates['BRIGHTNESS'] == -1), 'BRIGHTNESS'] = 3\n",
        "df_noDuplicates.loc[(df_noDuplicates['Clear'] == 1) & (df_noDuplicates['DAY'] == 0) & (df_noDuplicates['BRIGHTNESS'] == -1), 'BRIGHTNESS'] = 1\n",
        "\n",
        "severity_reorder = {1:3, 2:2, 3:1, 4:1}\n",
        "df_noDuplicates['MAX_SEVERITY_LEVEL'].replace(severity_reorder, inplace=True)\n",
        "df_noDuplicates.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h24ZZ3ohqPEe"
      },
      "outputs": [],
      "source": [
        "# Sort by date and output data to CSV\n",
        "df_noDuplicates.head()\n",
        "df_noDuplicates.to_csv('cleaned.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
