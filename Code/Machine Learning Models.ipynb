{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaa2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install dabl\n",
    "import dabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc, balanced_accuracy_score\n",
    "from sklearn.model_selection import GroupKFold,train_test_split,cross_validate\n",
    "from sklearn import tree #decision Tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d24c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "fullpath = os.path.abspath(r\"C:\\Users\\tansh\\Downloads\\Telegram Desktop\\cleaned_final (2).csv\") #change path\n",
    "start_time = time.time()\n",
    "df = pd.read_csv(fullpath)\n",
    "log_time = (time.time() - start_time)\n",
    "print(log_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138febb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = df.drop(columns = [\"CONS_ZONE_SPD_LIM\"],axis = 1)\n",
    "#selected_df = selected_df.drop(df.columns[0],axis = 1) #drop axis\n",
    "selected_df = selected_df[selected_df[\"MAX_SEVERITY_LEVEL\"]!= 9]\n",
    "print(selected_df.info())\n",
    "X_train = selected_df.drop('MAX_SEVERITY_LEVEL',axis=1)\n",
    "y_train = selected_df.MAX_SEVERITY_LEVEL\n",
    "\n",
    "# Count NaN values\n",
    "# Find columns with more than one null value\n",
    "cols_with_nulls = X_train.columns[X_train.isnull().sum() > 1]\n",
    "\n",
    "# Sum the number of null values for those columns\n",
    "null_counts = X_train[cols_with_nulls].isnull().sum()\n",
    "null_counts\n",
    "\n",
    "X_train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f33cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from prince import FAMD\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = selected_df.drop(\"MAX_SEVERITY_LEVEL\",axis = 1)\n",
    "y = selected_df.MAX_SEVERITY_LEVEL\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit a Random Forest model to assess feature importance\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Get feature importances from the trained Random Forest model\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=X_train_class.columns)\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "# Select the top 50 features based on feature importances\n",
    "top_features = feature_importances.head(50).index.tolist()\n",
    "'''\n",
    "# Apply FAMD for dimensionality reduction\n",
    "#famd = FAMD(n_components=2)\n",
    "#famd.fit(X)  # Fit FAMD to the data\n",
    "#X_famd = famd.fit_transform(X)\n",
    "\n",
    "# Train a Decision Tree model on the reduced feature set\n",
    "X_train_famd, X_test_famd, y_train, y_test = train_test_split(X[top_features], y, test_size=0.2, random_state=42)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_famd, y_train)\n",
    "\n",
    "# Predict using the trained Decision Tree model\n",
    "y_pred = dt.predict(X_test_famd)\n",
    "print(X_test_famd)\n",
    "print(y_pred)\n",
    "# Evaluate the performance of the Decision Tree model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "'''\n",
    "x_train,x_test,y_train,y_test = train_test_split(X[top_features],y,test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2590c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "feature_importances.iloc[:] = feature_importances.iloc[:].round(4)\n",
    "\n",
    "print(feature_importances)\n",
    "\n",
    "#feature_importances[]=feature_importances[feature_importances[]]\n",
    "X_train.info()\n",
    "plt.plot(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0779e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM (w RandomForest input) (BALANCED)\n",
    "\n",
    "# Fit a Random Forest model to assess feature importance\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Get feature importances from the trained Random Forest model\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=x_train.columns)\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "best_train= 0\n",
    "best_acc = 0\n",
    "best_no_of_samples = 0\n",
    "top_features = feature_importances.head(50).index.tolist()\n",
    "x_train_selected = x_train[top_features]\n",
    "\n",
    "# LightGBM training\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': 4, \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(x_train_selected, label=y_train)\n",
    "test_data = lgb.Dataset(x_test[top_features], label=y_test)\n",
    "model = lgb.train(params, train_data, valid_sets=test_data, num_boost_round=1000, early_stopping_rounds=100)\n",
    "\n",
    "y_pred = model.predict(x_test[top_features])\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = balanced_accuracy_score(y_pred_class,y_test)\n",
    "precision = precision_score(y_test, y_pred_class, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_class, average='weighted')\n",
    "f1_score = f1_score(y_test, y_pred_class, average='weighted')\n",
    "confusion_mat = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1-score: \",(f1_score))\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print('best accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eef54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from scipy.stats import randint as sp_randint \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_dist = {\"max_depth\": [5, 7, 9, 11, 13, 15, -1],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "                \"class_weight\": ['balanced']}\n",
    "\n",
    "# define the randomized search with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(tree, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "# fit the randomized search on the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# evaluate the best model on the test data\n",
    "best_model = random_search.best_estimator_\n",
    "test_acc = best_model.score(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Compute predictions using the best_rf model\n",
    "predictions = random_search.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee734f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision, recall, and F1-score\n",
    "from sklearn import metrics\n",
    "#accuracy = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "#f1SCORE = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "#print(\"F1-score: {:.4f}\".format(f1SCORE))\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "\n",
    "\n",
    "# print the best hyperparameters\n",
    "print('Best hyperparameters:', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f754b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from scipy.stats import randint as sp_randint \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],  # Number of features to consider for the best split\n",
    "    'class_weight': ['balanced']  # Class weight option\n",
    "}\n",
    "\n",
    "\n",
    "# define the randomized search with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "# fit the randomized search on the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# evaluate the best model on the test data\n",
    "best_model = random_search.best_estimator_\n",
    "test_acc = best_model.score(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Compute predictions using the best_rf model\n",
    "predictions = random_search.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision, recall, and F1-score\n",
    "\n",
    "balanced = metrics.balanced_accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "#f1_score = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(\"Balanced Accuracy: {:.4f}\".format(balanced))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "#print(\"F1-score: {:.4f}\".format(f1_score))\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print('Best hyperparameters:', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281066c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow (Neural Network)\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Random Forest for feature selection\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "feature_importances = pd.Series(rf.feature_importances_, index=x_train.columns)\n",
    "feature_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "top_features = feature_importances.head(50).index.tolist()\n",
    "x_train_selected = x_train[top_features]\n",
    "\n",
    "# This custom class is adapted by user Aaron Keesing on Stack Overflow: https://stackoverflow.com/questions/59339531/balanced-accuracy-score-in-tensorflow\n",
    "class BalancedSparseCategoricalAccuracy(keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_sparse_categorical_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(x_train_selected.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=[BalancedSparseCategoricalAccuracy(name='balanced_sparse_categorical_accuracy')])\n",
    "\n",
    "model.fit(x_train_selected, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test[top_features], y_test)\n",
    "y_pred = model.predict(x_test[top_features])\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "precision = precision_score(y_test, y_pred_class, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_class, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_class, average='weighted')\n",
    "\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "print(\"Best Precision: \", precision)\n",
    "print(\"Best Recall: \", recall)\n",
    "print(\"Best F1: \", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
